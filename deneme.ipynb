{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Preprocessing for Vehicle Dataset\n",
    "\n",
    "This notebook demonstrates the process of cleaning and preprocessing a vehicle dataset. We'll go through several steps including data loading, handling missing values, data type conversions, and group-based imputations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')\n",
    "sns.set_palette(\"deep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "file_path = r\"C:\\Users\\90545\\Desktop\\Emir\\Personal_Files\\Data_Scraping_Projects\\edmunds_project\\scraping\\edmunds_scraped_data_last.csv\"\n",
    "data = pd.read_csv(file_path, low_memory=False, index_col=0)\n",
    "df = data.copy()\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initial Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define columns to drop\n",
    "columns_to_drop = [\"vid\", \"vin\", \"listingUrl\", \"dealerInfo.address.street\",\n",
    "                   \"dealerInfo.productFeatures.verified\", \"dealerInfo.address.stateName\",\n",
    "                   \"stockNumber\", \"inTransit\", \"vehicleInfo.styleInfo.fuel.epaCombinedMPG\",\n",
    "                   \"vehicleInfo.styleInfo.fuel.epaCityMPG\", \"vehicleInfo.styleInfo.fuel.epaHighwayMPG\", \"historyInfo.personalUseOnly\"]\n",
    "\n",
    "# Drop columns\n",
    "df.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "print(f\"Dataset shape after dropping columns: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Handling Missing Values and Special Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace '{}' with np.nan or special values\n",
    "replacement_dict = {\n",
    "    \"prices.displayPrice\": np.nan,\n",
    "    \"vehicleInfo.vehicleColors.exterior.genericName\": np.nan,\n",
    "    \"vehicleInfo.vehicleColors.interior.genericName\": np.nan,\n",
    "    \"historyInfo.historyProvider\": \"USER\",\n",
    "    \"vehicleInfo.mileage\": np.nan,\n",
    "    \"historyInfo.usageType\": \"Unknown_Usage_Type\",\n",
    "    \"prices.baseMsrp\": np.nan,\n",
    "    \"prices.totalMsrp\": np.nan,\n",
    "    \"prices.loan.payment\": np.nan,\n",
    "    \"historyInfo.ownerText\": \"Unknown\",\n",
    "    \"sellersComments\": np.nan\n",
    "}\n",
    "\n",
    "for col, value in replacement_dict.items():\n",
    "    df[col] = df[col].replace(\"{}\", value)\n",
    "\n",
    "# Special case for engine type\n",
    "df.loc[df[\"vehicleInfo.partsInfo.engineSize\"].str.contains(r\"\\{\\}\") & \n",
    "       (df[\"vehicleInfo.partsInfo.fuelType\"] == \"{}\") & \n",
    "       df[\"vehicleInfo.styleInfo.style\"].str.contains(r'\\d+cyl'), \n",
    "       \"vehicleInfo.partsInfo.engineType\"] = \"gas\"\n",
    "\n",
    "print(\"Missing value handling complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Type Conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert specific columns to float\n",
    "float_columns = [\"prices.displayPrice\", \"vehicleInfo.mileage\", \"prices.totalMsrp\", \"prices.baseMsrp\", \"prices.loan.payment\"]\n",
    "for col in float_columns:\n",
    "    df[col] = df[col].astype(\"float\")\n",
    "\n",
    "print(\"Data type conversions complete.\")\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Handling Electric Vehicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle electric vehicles\n",
    "columns_to_replace = ['vehicleInfo.partsInfo.engineSize', 'vehicleInfo.partsInfo.cylinders']\n",
    "df[columns_to_replace] = df[columns_to_replace].replace('{}', np.nan)\n",
    "df.loc[df['vehicleInfo.partsInfo.engineType'] == 'electric', columns_to_replace] = \\\n",
    "    df.loc[df['vehicleInfo.partsInfo.engineType'] == 'electric', columns_to_replace].fillna(0)\n",
    "\n",
    "print(\"Electric vehicle handling complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Group-based Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_column(df, column, group_cols):\n",
    "    df[column] = df[column].replace(\"{}\", np.nan)\n",
    "    \n",
    "    is_numeric = pd.api.types.is_numeric_dtype(df[column])\n",
    "    \n",
    "    if is_numeric:\n",
    "        df[column] = df.groupby(group_cols)[column].transform(\n",
    "            lambda x: x.fillna(x.median())\n",
    "        )\n",
    "        df[column] = df[column].fillna(df[column].median())\n",
    "    else:\n",
    "        df[column] = df.groupby(group_cols)[column].transform(\n",
    "            lambda x: x.fillna(x.mode().iloc[0] if not x.mode().empty else np.nan)\n",
    "        )\n",
    "        overall_mode = df[column].mode().iloc[0] if not df[column].mode().empty else \"Unknown\"\n",
    "        df[column] = df[column].fillna(overall_mode)\n",
    "    \n",
    "    return df\n",
    "\n",
    "group_cols = ['vehicleInfo.styleInfo.make', 'vehicleInfo.styleInfo.model', 'vehicleInfo.styleInfo.year']\n",
    "\n",
    "columns_to_process = [\n",
    "    'vehicleInfo.vehicleColors.exterior.genericName', 'vehicleInfo.vehicleColors.interior.genericName',\n",
    "    'vehicleInfo.partsInfo.driveTrain', 'vehicleInfo.partsInfo.cylinders', 'vehicleInfo.partsInfo.engineSize',\n",
    "    'vehicleInfo.partsInfo.engineType', 'vehicleInfo.partsInfo.fuelType', 'vehicleInfo.partsInfo.transmission',\n",
    "    'vehicleInfo.styleInfo.trim', 'vehicleInfo.styleInfo.style', 'vehicleInfo.styleInfo.year',\n",
    "    'vehicleInfo.styleInfo.bodyType', 'vehicleInfo.styleInfo.vehicleStyle', 'vehicleInfo.styleInfo.numberOfSeats',\n",
    "    'historyInfo.ownerText', 'historyInfo.usageType', 'historyInfo.historyProvider', 'historyInfo.salvageHistory',\n",
    "    'historyInfo.frameDamage', 'historyInfo.lemonHistory', 'historyInfo.theftHistory', 'historyInfo.accidentText',\n",
    "    'computedDisplayInfo.priceValidation.dealType', 'prices.displayPrice', 'prices.loan.payment',\n",
    "    'prices.baseMsrp', 'prices.totalMsrp', 'vehicleInfo.mileage'\n",
    "]\n",
    "\n",
    "for column in columns_to_process:\n",
    "    df = process_column(df, column, group_cols)\n",
    "    print(f\"Processed {column}. NaN count: {df[column].isna().sum()}\")\n",
    "\n",
    "print(\"Group-based imputation complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Final Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Final dataset shape: {df.shape}\")\n",
    "print(\"\\nMissing values summary:\")\n",
    "print(df.isna().sum())\n",
    "\n",
    "# Display a heatmap of missing values\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(df.isna(), yticklabels=False, cbar=False, cmap='viridis')\n",
    "plt.title('Missing Value Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusion\n",
    "\n",
    "We've successfully cleaned and preprocessed the vehicle dataset. The main steps included:\n",
    "1. Loading the data\n",
    "2. Initial data cleaning (dropping unnecessary columns)\n",
    "3. Handling missing values and special cases\n",
    "4. Data type conversions\n",
    "5. Special handling for electric vehicles\n",
    "6. Group-based imputation for remaining missing values\n",
    "\n",
    "The dataset is now ready for further analysis or modeling tasks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
